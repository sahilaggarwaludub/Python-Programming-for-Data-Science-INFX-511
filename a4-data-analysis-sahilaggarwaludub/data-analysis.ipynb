{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a4 - Data Analysis\n",
    "Fill in the below code cells as specified. Note that cells may utilize variables and functions defined in previous cells; we should be able to use the `Kernal > Restart & Clear All` menu item followed by `Cell > Run All` to execute your entire notebook and see the correct output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Numbers\n",
    "For this part of the assignment, you will analyze some numeric data (counts of library holdings) to investiate how the distribution of numbers in natural data sets obeys the counter-intuitive [Benford's Law](https://plus.maths.org/content/os/issue9/features/benford/index). \n",
    "\n",
    "<small>(This exercise was adapted from Steve Wolfman).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`holdings_data`** which is a **list** of the contents of the **`data/libraryholdings.txt`** file included in the repository (each line in the file should be a single element in the list). You will need to open up the file and read its contents into a list. You should specify a _local path_ to the file (from this notebook's location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdings_data = []\n",
    "with open('data/libraryholdings.txt') as file:\n",
    "    for line in file:\n",
    "        holdings_data.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first **ten** items from the `holdings_data` list, each on its own line. (Note that there may be extra line breaks that are included in the data items themselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['(* Library holdings (# of books in each library), *)\\n',\n",
       " '(* collected by Christian Ayotte.                 *)\\n',\n",
       " '(* Labels not available.                          *)\\n',\n",
       " '\\n',\n",
       " '12201\\n',\n",
       " '600778\\n',\n",
       " '14926\\n',\n",
       " '37863\\n',\n",
       " '14866\\n',\n",
       " '9896\\n']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(holdings_data))\n",
    "holdings_data[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **slice operator (`:`)** to remove the \"heading\" and blank elements from the beginning of the data list, leaving only the list of numbers. The remaining values should continue to be stored (re-stored) in the `holdings_data` variable. Output the new first element in `holdings_data` to demonstrate that it is the first number in the data set.\n",
    "- The values in the list _should_ be strings rather than an integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9138\n"
     ]
    }
   ],
   "source": [
    "holdings_data = holdings_data[4:]\n",
    "print(len(holdings_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(holdings_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`lead_digit_counts`** that is a dictionary whose keys are _strings_ of each digit (`\"0\"`, `\"1\"`, `\"2\"`, etc.), and whose values are all the number `0`. You can do this directly or with a loop. Print out the variable after you create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 0,\n",
       " '2': 0,\n",
       " '3': 0,\n",
       " '4': 0,\n",
       " '5': 0,\n",
       " '6': 0,\n",
       " '7': 0,\n",
       " '8': 0,\n",
       " '9': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lead_digit_counts={}\n",
    "for i in range(0,10):\n",
    "    lead_digit_counts[str(i)]=0\n",
    "lead_digit_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of times each digit appears as the _first digit_ in a value of the `holdings_data` list, storing those counts in the `lead_digit_counts` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(holdings_data)):\n",
    "    for j in range(0,10):\n",
    "        if(holdings_data[i][0]==str(j)):\n",
    "            lead_digit_counts[str(j)]=lead_digit_counts[str(j)]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 3056, '2': 1606, '3': 1018, '4': 801, '5': 640, '6': 560, '7': 502, '8': 503, '9': 452}\n"
     ]
    }
   ],
   "source": [
    "print(lead_digit_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a loop to print out each count in `lead_digit_counts` with the format:\n",
    "```\n",
    "X values have a leading digit of digit Y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 values have a leading digit of digit 0\n",
      "3056 values have a leading digit of digit 1\n",
      "1606 values have a leading digit of digit 2\n",
      "1018 values have a leading digit of digit 3\n",
      "801 values have a leading digit of digit 4\n",
      "640 values have a leading digit of digit 5\n",
      "560 values have a leading digit of digit 6\n",
      "502 values have a leading digit of digit 7\n",
      "503 values have a leading digit of digit 8\n",
      "452 values have a leading digit of digit 9\n"
     ]
    }
   ],
   "source": [
    "for key,value in lead_digit_counts.items():\n",
    "    print(value, 'values have a leading digit of digit', key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the _percentage_ of values in the the library holdings data set that have a leading digit **`1`** (round to 2 decimal places). Is this value as predicted by Benford's law?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = lead_digit_counts['1']/len(holdings_data)\n",
    "round(n*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes it is approximately equal to the value predicted by Benfords law which is 30%. (Source - Wikipedia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extra credit challenge:*** Create a single variable `digit_position_counts` that contains the number of times that each digit 0 through 9 appears in _each_ position in the data set. E.g., a `1` appears in the 1st position 3056 times and in the second position 1005 times; a `2` appears in the 1st position 1606 times and in the second position 1044 times.\n",
    "\n",
    "Use this variable to print a \"table\" of the percentage of the time each position contains each digit (e.g., the 1st digit is a `1` 33.44% of the time, a `2` 17.57% of the time, etc).\n",
    "\n",
    "Note that for this extra challenge it is up to you to determine an appropriate data structure (e.g., how to combine dictionaries and lists and tuples) for representing this table. Be sure and include comments explaining your work.\n",
    "\n",
    "Only attempt this problem once you have completed everything else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0     1     2     3    4    5    6    7    8    9\n",
      "1      0  3056  1606  1018  801  640  560  502  503  452\n",
      "2   1162  1005  1044   971  879  889  859  795  762  772\n",
      "3   1150   890   890   901  866  930  917  868  903  820\n",
      "4   1299   837   885   844  885  910  782  927  846  906\n",
      "5   1052   660   713   687  720  820  762  738  719  742\n",
      "6    161   140   140   153  137  150  126  166  144  164\n",
      "7     10    14     8     7    5    8   15    9   11    6\n",
      "8      0     0     0     0    0    0    0    0    0    1\n",
      "9      0     0     0     0    0    0    0    0    0    0\n",
      "10     0     0     0     0    0    0    0    0    0    0\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of dictionaries, where each dictionary has position counts for each digit\n",
    "list_of_dicts = []\n",
    "for x in range(0,10):\n",
    "    digit_count={'0':0,'1':0,'2':0,'3':0,'4':0,'5':0,'6':0,'7':0,'8':0,'9':0}\n",
    "    for i in range(0,len(holdings_data)):\n",
    "        for j in range(0,10):\n",
    "            if(len(holdings_data[i])>x):\n",
    "                if(holdings_data[i][x]==str(j)):\n",
    "                    digit_count[str(j)]=digit_count[str(j)] + 1\n",
    "    list_of_dicts.append(digit_count)\n",
    "\n",
    "# Using pandas to create a table which has coloumns as digits and rows as positions\n",
    "import pandas as pd\n",
    "digit_position_counts = pd.DataFrame(list_of_dicts,index=range(1,11))\n",
    "print(digit_position_counts)\n",
    "\n",
    "#Calculating percentages for each element in the dataframe\n",
    "b = []\n",
    "for i in range(0,10):\n",
    "    b.append(digit_position_counts.iloc[i].sum())\n",
    "len(b)\n",
    "c = digit_position_counts.divide(b,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.442766</td>\n",
       "      <td>17.574962</td>\n",
       "      <td>11.140293</td>\n",
       "      <td>8.765594</td>\n",
       "      <td>7.003721</td>\n",
       "      <td>6.128256</td>\n",
       "      <td>5.493543</td>\n",
       "      <td>5.504487</td>\n",
       "      <td>4.946378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.716130</td>\n",
       "      <td>10.998030</td>\n",
       "      <td>11.424819</td>\n",
       "      <td>10.625958</td>\n",
       "      <td>9.619173</td>\n",
       "      <td>9.728606</td>\n",
       "      <td>9.400306</td>\n",
       "      <td>8.699934</td>\n",
       "      <td>8.338805</td>\n",
       "      <td>8.448238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.588944</td>\n",
       "      <td>9.742748</td>\n",
       "      <td>9.742748</td>\n",
       "      <td>9.863164</td>\n",
       "      <td>9.480022</td>\n",
       "      <td>10.180624</td>\n",
       "      <td>10.038314</td>\n",
       "      <td>9.501916</td>\n",
       "      <td>9.885057</td>\n",
       "      <td>8.976464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.241859</td>\n",
       "      <td>9.176625</td>\n",
       "      <td>9.702883</td>\n",
       "      <td>9.253371</td>\n",
       "      <td>9.702883</td>\n",
       "      <td>9.976976</td>\n",
       "      <td>8.573621</td>\n",
       "      <td>10.163359</td>\n",
       "      <td>9.275299</td>\n",
       "      <td>9.933121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.818468</td>\n",
       "      <td>8.669381</td>\n",
       "      <td>9.365559</td>\n",
       "      <td>9.024038</td>\n",
       "      <td>9.457507</td>\n",
       "      <td>10.771050</td>\n",
       "      <td>10.009195</td>\n",
       "      <td>9.693945</td>\n",
       "      <td>9.444371</td>\n",
       "      <td>9.746486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.871033</td>\n",
       "      <td>9.453072</td>\n",
       "      <td>9.453072</td>\n",
       "      <td>10.330858</td>\n",
       "      <td>9.250506</td>\n",
       "      <td>10.128292</td>\n",
       "      <td>8.507765</td>\n",
       "      <td>11.208643</td>\n",
       "      <td>9.723160</td>\n",
       "      <td>11.073599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.752688</td>\n",
       "      <td>15.053763</td>\n",
       "      <td>8.602151</td>\n",
       "      <td>7.526882</td>\n",
       "      <td>5.376344</td>\n",
       "      <td>8.602151</td>\n",
       "      <td>16.129032</td>\n",
       "      <td>9.677419</td>\n",
       "      <td>11.827957</td>\n",
       "      <td>6.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0          1          2          3         4          5  \\\n",
       "1    0.000000  33.442766  17.574962  11.140293  8.765594   7.003721   \n",
       "2   12.716130  10.998030  11.424819  10.625958  9.619173   9.728606   \n",
       "3   12.588944   9.742748   9.742748   9.863164  9.480022  10.180624   \n",
       "4   14.241859   9.176625   9.702883   9.253371  9.702883   9.976976   \n",
       "5   13.818468   8.669381   9.365559   9.024038  9.457507  10.771050   \n",
       "6   10.871033   9.453072   9.453072  10.330858  9.250506  10.128292   \n",
       "7   10.752688  15.053763   8.602151   7.526882  5.376344   8.602151   \n",
       "8    0.000000   0.000000   0.000000   0.000000  0.000000   0.000000   \n",
       "9         NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "10        NaN        NaN        NaN        NaN       NaN        NaN   \n",
       "\n",
       "            6          7          8           9  \n",
       "1    6.128256   5.493543   5.504487    4.946378  \n",
       "2    9.400306   8.699934   8.338805    8.448238  \n",
       "3   10.038314   9.501916   9.885057    8.976464  \n",
       "4    8.573621  10.163359   9.275299    9.933121  \n",
       "5   10.009195   9.693945   9.444371    9.746486  \n",
       "6    8.507765  11.208643   9.723160   11.073599  \n",
       "7   16.129032   9.677419  11.827957    6.451613  \n",
       "8    0.000000   0.000000   0.000000  100.000000  \n",
       "9         NaN        NaN        NaN         NaN  \n",
       "10        NaN        NaN        NaN         NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#multiply each element by hundred\n",
    "table = c.multiply(100,axis=0)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Life Expectancy\n",
    "For this part of the assignment, you'll work with data about the life expectancy (in years) for each country in the world in the years 1960 and 2013. Note that this can be really [fun](http://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen.html) data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is found in a [.csv](https://en.wikipedia.org/wiki/Comma-separated_values) file: a plain-text data format where each line represents a record (row) of data and where feature (column) is separated by a comma.\n",
    "\n",
    "Read in the contents of the **`data/life_expectancy.csv`** data file, and use it to construct a **list** called **`life_expectancy_list`**. Each element in this list should be a **dictionary** (one for each row in the `csv` file) with the following keys and values:\n",
    "\n",
    "- a key `'country'` whose value is the name of the country (as a string)\n",
    "- a key `'le_1960'` whose value is the life expectancy in 1960 (as a float)\n",
    "- a key `'le_2013'` whose value is the life expectancy in 2013 (as a float)\n",
    "\n",
    "Thus the first record should look like:\n",
    "```\n",
    "{'country': 'Aruba', 'le_1960': 65.56936585, 'le_2013': 75.33217073}\n",
    "```\n",
    "\n",
    "You should use the **`csv`** module to read this file and break up each row into different values. See [the documentation](https://docs.python.org/3/library/csv.html) for an example of how to do this. Print out the _first row_ of your list as a demonstration that you've processed the data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Aruba', 'le_1960': '65.56936585', 'le_2013': '75.33217073'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "life_expectancy_list=[]\n",
    "with open('data/life_expectancy.csv') as csvfile:\n",
    "    file = csv.reader(csvfile)\n",
    "    for row in file:\n",
    "            dictionary={}\n",
    "            dictionary['country']=row[0]\n",
    "            dictionary['le_1960']=row[-2]\n",
    "            dictionary['le_2013']=row[-1]\n",
    "            life_expectancy_list.append(dictionary)\n",
    "life_expectancy_list = life_expectancy_list[1:]            \n",
    "print(life_expectancy_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(life_expectancy_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add another item to each dictionary in the `life_expectancy_list` whose **key** is `change` and whose **value** is the change in life expectancy from 1960 to 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in life_expectancy_list:\n",
    "    a = float(i['le_2013']) - float(i['le_1960'])\n",
    "    i.update({'change':a})        \n",
    "#print(life_expectancy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`num_small_gain`** that stores the **number of countries** whose life expectancy did not improve by 5 years or more between 1960 and 2013. This will include counties whose life expectancy has worsened. Print out this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in life_expectancy_list:\n",
    "    if(i['change']<5):\n",
    "        a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "num_small_gain = len(a)\n",
    "print(num_small_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`most_improved`** that is the **name of the country** with the largest gain in life expectancy (between 1960 and 2013). Print out this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.07575609\n",
      "Maldives\n"
     ]
    }
   ],
   "source": [
    "b=[]\n",
    "for i in life_expectancy_list:\n",
    "    b.append(i['change'])\n",
    "max_val = max(b)\n",
    "print(max_val)\n",
    "\n",
    "for i in life_expectancy_list:\n",
    "    if(i['change']==max_val):\n",
    "            a = i['country']\n",
    "most_improved = a\n",
    "print(most_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`compare_country_le()`** that takes in the names of _two_ countries, and returns a **tuple** containing the following information:\n",
    "- the name of the country with the greater life expectancy,\n",
    "- the life expectancy in 2013 of that country\n",
    "- the difference between the life expectancies in 2013\n",
    "\n",
    "Use your function to print the comparison between the life expectancies of the _United States_ and _Cuba_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_country_le(first,second):\n",
    "    \"\"\"\n",
    "    Takes in the names of two countries, and returns a tuple containing the following information:\n",
    "    \n",
    "    -the name of the country with the greater life expectancy,\n",
    "    -the life expectancy in 2013 of that country\n",
    "    -the difference between the life expectancies in 2013\n",
    "    \n",
    "    \"\"\"\n",
    "    for i in life_expectancy_list:\n",
    "        if(i['country']==first):\n",
    "            first_country = i\n",
    "        elif(i['country']==second):\n",
    "            second_country = i\n",
    "    if(first_country['le_2013'] > second_country['le_2013']):\n",
    "        name=first_country['country']\n",
    "        life_exp = first_country['le_2013']\n",
    "    else:\n",
    "        name = second_country['country']\n",
    "        life_exp = second_country['le_2013']\n",
    "    diff = abs(float(first_country['le_2013'])-float(second_country['le_2013']))\n",
    "    return (name,life_exp,diff)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Cuba', '79.23926829', 0.39780487999999536)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_country_le('United States','Cuba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Readability\n",
    "For this part of the assignment, you will calculate the [readability](https://en.wikipedia.org/wiki/Readability) of a text document using the [Dale-Chall Readability Formula](http://www.readabilityformulas.com/new-dale-chall-readability-formula.php). This method determines how \"easy\" it is to read a particular (English) document by considering the length of sentences and how many of the words used are \"easy\" to understand (based on a pre-defined list of \"easy\" words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting real-world text documents into words and sentences is non-trivial (English is hard!). To make this easier, you should use the [Natural Language Toolkit (nltk)](http://www.nltk.org/index.html) module. This module is included with Anacaonda, but does require some additional data source files to be installed on your computer. You _should_ be able to do this by running the below cell (you only need to run it once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sahilaggarwal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sahilaggarwal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import download\n",
    "download('punkt')\n",
    "download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to load the list of \"easy\" words into memory. This list can be found in the **`data/dale-chall.txt`** file. Open this file and read its entire contents into a **list** variable (e.g., `easy_words_list`), where each element in the list is a single line (word) in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/dale-chall.txt\") as file:\n",
    "    easy_words_list = []\n",
    "    for line in file:\n",
    "        easy_words_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to \"look up\" easy words, convert the easy words list into a **dictionary** (e.g., `easy_words_dict`), where each **key** is a word, and each **value** is `True` (that the word is in the list).\n",
    "- Make sure you do not include newline characters in your keys!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_words_dict={}\n",
    "for i in easy_words_list:\n",
    "    easy_words_dict[i]=True\n",
    "#print(easy_words_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, define a dictionary **`readability_grade_dict`** to use for looking up the \"grade level\" associated with a readability score (see [this table](https://en.wikipedia.org/wiki/Dale%E2%80%93Chall_readability_formula#Formula)). This dictionary should have **keys** that are ___tuples___ giving the range of score for a particular grade (e.g., `(5.0, 5.9)`), and **values** that are ___strings___ representing the grade (e.g., `\"5th or 6th grade\"`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "readability_grade_dict={}\n",
    "readability_grade_dict[(0.0,4.9)]=\"4th grade or lower\"\n",
    "readability_grade_dict[(5.0,5.9)]=\"5th or 6th grade\"\n",
    "readability_grade_dict[(6.0,6.9)]=\"7th or 8th grade\"\n",
    "readability_grade_dict[(7.0,7.9)]=\"9th or 10th grade\"\n",
    "readability_grade_dict[(8.0,8.9)]=\"11th or 12th grade\"\n",
    "readability_grade_dict[(9.0,9.9)]=\"13th or 15th grade\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`print_grade()`** that takes in a readability score (a number greater than or equal to 0), and **prints** a string representing the grade associated with that score (from your `readability_grade_dict` dictionary).\n",
    "- _Hint:_ loop through the items in the dictionary and determine which \"tuple\" key has elements that the score falls between. Be sure and round to the nearest decimal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_grade(readibility_score):\n",
    "    \"\"\"\n",
    "    Takes in a readability score (a number greater than or equal to 0), and prints a string representing the grade associated with that score\n",
    "    \"\"\"\n",
    "    grade=0\n",
    "    if 0.0 < readibility_score < 9.9:\n",
    "        for i in readability_grade_dict.keys():\n",
    "            if i[0] < readibility_score < i[1]:\n",
    "                grade = readability_grade_dict[i]\n",
    "    else:\n",
    "        print(\"Invalid readability score\")\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4th grade or lower'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_grade(2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to calculate the readability scores! Define a function **`count_sentences()`** that counts the number of sentences in a string. Use the [sent_tokenize()](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.sent_tokenize) function from the `nltk.tokenize` module to break up a string into sentences (this is like the string `split()` function, but it splits into sentences rather than dividing by spaces).\n",
    "- For help and an example, see [this guide](http://textminingonline.com/dive-into-nltk-part-ii-sentence-tokenize-and-word-tokenize).\n",
    "- You do not need to do any extra processing beyond that provided by the `sent_tokenize()` function.\n",
    "- Test your function on a simple pair or trio of sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def count_sentences(text):\n",
    "    \"\"\"\n",
    "    Counts the number of sentences in a string - text\n",
    "    \"\"\"\n",
    "    sentences = sent_tokenize(text)\n",
    "    number_of_sentences = len(sentences)\n",
    "    return number_of_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`extract_words()`** that takes in a string and returns a _list_ of all of the words in that string. Use the [word_tokenize()](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize) function from the `nltk.tokenize` module to break up the string into words.\n",
    "- The `nltk` tokenizer includes each punctuation character (e.g., commas, periods) as individual \"words\". Your list should not include these items. You can use a string method to determine whether or not the word starts with a punctuation symbol, and if so exclude it. _Hint_ think about keeping good words, rather than throwing away the bad! Note that you do not need to do any special consideration for contractions or other words that include their own punctuation.\n",
    "- Test your function on a simple sentence (with punctuation!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "def extract_words(string1):\n",
    "    \"\"\"\n",
    "    Takes in a string (string 1) and returns a list of all of the words in that string\n",
    "    \"\"\" \n",
    "    list_words = word_tokenize(string1)\n",
    "    final_words=[]\n",
    "    for word in list_words:\n",
    "        if word[0].isalpha():\n",
    "            final_words.append(word.lower())\n",
    "    return final_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['damn', 'sahil', 'is', 'amazing']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_words('Damn!''- Sahil is @@@@@@@ Amazing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`count_easy_words()`** that takes in a _list_ of words as an argument and returns the number of words that are \"easy\".\n",
    "\n",
    "- Your function should look up each word in the `easy_words_dict` you defined earlier. _Do not look up words in the list_ (the dictionary is much faster!). Be careful to look up lowercase versions of the word.\n",
    "\n",
    "- Your function should handle detecting different parts of speech (e.g., plurals, different verb conjugations, etc.). You can do this by using the **`WordNetLemmatizer()`** function from the `nltk.stem.wordnet` module&mdash;which produces a \"lemmatizer\" object. You can call the **`lemmatize()`** method on this object to reduce a word to its \"base\" form. See [this example](https://pythonprogramming.net/lemmatizing-nltk-tutorial/). Note that you should reduce words to both their basic noun AND verb forms (you will need to call the function twice: once with `'n'` (noun) and once with `'v'` (verb) as the second argument!)\n",
    "\n",
    "- You can test your function on the word list: `['My','words','spoken','have','consequences']`, which should have 4 of the 5 words considered easy (not \"consequences\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_easy_words(words):\n",
    "    \"\"\"\n",
    "    Takes in a list of words (words) as an argument and returns the number of words that are \"easy\" comparing it with the \n",
    "    easy_words_dict defined earlier.\n",
    "    \"\"\"    \n",
    "    x=[]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words=map(lambda x:x.lower(),words)\n",
    "    for i in words:\n",
    "        a=lemmatizer.lemmatize(i,pos='v')\n",
    "        b=lemmatizer.lemmatize(i,pos='n')\n",
    "        if(a in easy_words_dict.keys()):\n",
    "            x.append(i)\n",
    "        elif(b in easy_words_dict.keys()):\n",
    "            x.append(i)\n",
    "    return len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_easy_words(['My','words','spoken','have','consequences'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`calc_readability_score()`** that takes in a string of text and returns a readability \"score\" for the test based on the [Dale-Chall readability formula](https://en.wikipedia.org/wiki/Dale%E2%80%93Chall_readability_formula#Formula). Call your previous functions to calculate the number of sentences, total words, and number of difficult (not easy) words.\n",
    "- Don't forget to adjust the score if the text is more than 5% difficult words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_readability_score(text):\n",
    "    \"\"\"\n",
    "    Takes in a string of text and returns a readability \"score\" for the test based on the Dale-Chall readability formula.\n",
    "    \"\"\"\n",
    "    const_1 = 0.1579\n",
    "    const_2 = 0.0496\n",
    "    no_of_sentences = count_sentences(text)\n",
    "    words = extract_words(text)\n",
    "    no_of_words=len(words)\n",
    "    no_of_easy_words = count_easy_words(words)\n",
    "    no_of_diff_words = no_of_words-no_of_easy_words\n",
    "    perc_diff = (no_of_diff_words/no_of_words)*100\n",
    "    perc_words = (no_of_words/no_of_sentences)\n",
    "    score = (perc_diff*const_1) + (perc_words*const_2)\n",
    "    if (perc_diff > 5 ):\n",
    "        score+=3.6365\n",
    "    print(no_of_sentences)\n",
    "    print(no_of_words)\n",
    "    print(no_of_diff_words)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the text of the `data/alice.txt` file (the full text of Alice in Wonderland) _as a single string_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/alice.txt','r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (extract_words(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the readability score for the `alice.txt` file and print it out. Then print out the reading grade associated with that score. Use your previously-defined functions!\n",
    "- For testing, note that my calculations show `alice.txt` has 977 sentences and 27198 words, of which 3610 are difficult. This leads to a readability score of ~7.113."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977\n",
      "27198\n",
      "3610\n",
      "7.113090902410715\n"
     ]
    }
   ],
   "source": [
    "grade = calc_readability_score(data)\n",
    "print(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9th or 10th grade'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_grade(grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note that this result may not be an especially accurate model of a text's readability&mdash;after all, it's just based on a simple estimation!_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
